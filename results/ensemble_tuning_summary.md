# 随机森林集成模型调优总结

## 实验目标

本次实验旨在通过不同的参数配置和集成方法，寻找最佳的随机森林模型配置，以提高对工具磨损的预测性能。

## 实验过程

我们进行了一系列的调优实验，包括网格搜索超参数优化和不同集成学习方法的对比实验。主要实验包括：

1. **网格搜索参数优化**：通过5760种不同参数组合的搜索，寻找单个随机森林模型的最佳配置
2. **堆叠集成实验**：使用不同基础模型配置的堆叠集成方法
3. **投票集成实验**：测试带权重的投票集成方法
4. **模拟XGBoost特性**：在集成模型中添加具有XGBoost特性的随机森林模型

## 实验结果对比

下表展示了各种模型配置的性能指标对比：

| 模型配置                                | MAE      | RMSE     | R²       |
|---------------------------------------|----------|----------|----------|
| 网格搜索优化单一模型                    | 20.8388  | 24.8182  | 0.6166   |
| 原始堆叠集成模型                        | 19.0535  | 22.8843  | 0.6741   |
| 网格搜索参数+堆叠集成                   | 21.3400  | 25.0784  | 0.6086   |
| 投票集成模型                           | 20.9746  | 25.2443  | 0.6034   |
| 堆叠集成+模拟XGBoost模型               | 19.1065  | 22.9185  | 0.6731   |

## 最佳配置分析

根据实验结果，我们发现：

1. **最佳集成配置**：原始的堆叠集成模型（MAE=19.0535, R²=0.6741）和增强版堆叠集成模型（MAE=19.1065, R²=0.6731）性能最佳，两者非常接近。

2. **最佳集成模型配置**：
   - 集成方法：堆叠（Stacking）
   - 基础模型配置：
     ```yaml
     - n_estimators: 300, max_depth: 25
     - n_estimators: 500, max_depth: 20
     - n_estimators: 700, max_depth: 15
     ```
   - 元模型：线性回归

3. **关键发现**：
   - 单一参数优化效果有限，最佳参数组合并不一定在集成模型中表现最佳
   - 堆叠集成比投票集成更有效
   - 添加模拟XGBoost特性的模型可以略微改善性能，但提升有限
   - 集成模型对训练-测试分布差异的鲁棒性略高

## 性能瓶颈分析

所有模型均未达到性能阈值（MAE < 5.0, RMSE < 5.0, R² > 0.85），主要原因可能包括：

1. **特征限制**：当前特征可能不足以充分表示工具磨损的复杂模式
2. **数据分布偏移**：训练集（c1, c4）和测试集（c6）之间可能存在显著的数据分布差异
3. **模型局限性**：即使是集成模型也难以捕捉工具磨损的非线性、时序特性

## 下一步建议

1. **特征工程增强**：
   - 添加时序特征、趋势特征
   - 应用更先进的信号处理技术提取频域特征
   - 考虑添加领域专家建议的特征

2. **数据预处理改进**：
   - 实施更有效的离群值处理
   - 尝试不同的标准化/归一化方法
   - 考虑数据增强技术

3. **深度学习探索**：
   - 尝试LSTM或GRU以捕捉时序模式
   - 探索1D-CNN提取信号特征

4. **异构集成**：
   - 结合非树模型（如SVM, KNN）进行异构集成
   - 实现多级堆叠集成

## 结论

随机森林集成模型在工具磨损预测任务上表现相对稳定，最佳模型达到约19.1的MAE和0.67的R²，这比单一模型有显著提升。然而，要达到工业应用标准还需进一步改进，特别是在特征工程和模型选择方面。 